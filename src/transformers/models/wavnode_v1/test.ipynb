{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a016109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Config not found for wavnode. You can manually add it to HARDCODED_CONFIG_FOR_MODELS in utils/args_doc.py\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import torch\n",
    "from transformers.models.wavnode.modeling_wavnode import WavNodeEncoder\n",
    "from transformers.models.wavnode.configuration_wavnode import WavNodeConfig\n",
    "\n",
    "use_cuda = True\n",
    "# use_mps = False\n",
    "if torch.cuda.is_available() and use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71446eba",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GLU.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      6\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: GLU.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "m = nn.GLU()\n",
    "a = torch.randn(4, 2)\n",
    "b = torch.randn(4, 2)\n",
    "output = m(a, b)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d8a2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(16, 200, 768).to(device)\n",
    "t = torch.linspace(0, 1, 24 + 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3f95eafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to get attention matrix, please set sdpa to False.\n",
      "in LayerNorm, rank doesn't affect the dimension of weights and biases\n",
      "in LayerNorm, rank doesn't affect the dimension of weights and biases\n"
     ]
    }
   ],
   "source": [
    "config = WavNodeConfig()\n",
    "config.use_sdpa = True\n",
    "config.step_method = \"midpoint\"\n",
    "ode = WavNodeEncoder(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6dadf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 200, 768])\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "result = ode(x, t, output_hidden_states=True)\n",
    "\n",
    "print(result.last_hidden_state.shape)\n",
    "print(len(result.hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99654344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(result.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef857c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([16, 200, 768])\n",
      "tensor(1652.2616, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "1 torch.Size([16, 200, 768])\n",
      "tensor(1653.3345, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "2 torch.Size([16, 200, 768])\n",
      "tensor(1655.6426, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "3 torch.Size([16, 200, 768])\n",
      "tensor(1659.0763, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "4 torch.Size([16, 200, 768])\n",
      "tensor(1664.2324, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "5 torch.Size([16, 200, 768])\n",
      "tensor(1670.4220, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "6 torch.Size([16, 200, 768])\n",
      "tensor(1678.2570, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "7 torch.Size([16, 200, 768])\n",
      "tensor(1686.8905, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "8 torch.Size([16, 200, 768])\n",
      "tensor(1697.0480, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "9 torch.Size([16, 200, 768])\n",
      "tensor(1708.0249, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "10 torch.Size([16, 200, 768])\n",
      "tensor(1719.3588, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "11 torch.Size([16, 200, 768])\n",
      "tensor(1732.8145, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "12 torch.Size([16, 200, 768])\n",
      "tensor(1746.8710, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "13 torch.Size([16, 200, 768])\n",
      "tensor(1762.1217, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "14 torch.Size([16, 200, 768])\n",
      "tensor(1778.8636, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "15 torch.Size([16, 200, 768])\n",
      "tensor(1795.2139, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "16 torch.Size([16, 200, 768])\n",
      "tensor(1812.6320, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "17 torch.Size([16, 200, 768])\n",
      "tensor(1831.5321, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "18 torch.Size([16, 200, 768])\n",
      "tensor(1852.1896, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "19 torch.Size([16, 200, 768])\n",
      "tensor(1871.9977, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "20 torch.Size([16, 200, 768])\n",
      "tensor(1892.8883, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "21 torch.Size([16, 200, 768])\n",
      "tensor(1914.2297, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "22 torch.Size([16, 200, 768])\n",
      "tensor(1935.9860, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "23 torch.Size([16, 200, 768])\n",
      "tensor(1960.3853, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "24 torch.Size([16, 200, 768])\n",
      "tensor(1985.0084, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i,emb in enumerate(result.hidden_states):\n",
    "    print(i, emb.shape)\n",
    "    print(emb.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc29049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
